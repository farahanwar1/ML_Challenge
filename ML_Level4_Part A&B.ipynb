{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d95c410",
   "metadata": {},
   "source": [
    "# **LEVEL 4** 💻"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6b6e5",
   "metadata": {},
   "source": [
    "### 🔷 PART A : PDF Text Extraction and Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e77bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.11.5)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n"
     ]
    }
   ],
   "source": [
    "# Install pdfplumber for PDF text extraction\n",
    "!pip install pdfplumber\n",
    "import pdfplumber       # Library for PDF extraction\n",
    "import pandas as pd     # Library for handling data in DataFrame\n",
    "import re       # Regular expressions for pattern matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262b0de",
   "metadata": {},
   "source": [
    "Choose the PDF desired to get extracted in the below cell code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7a2013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the PDF file\n",
    "pdf_path = \"police_reports/police_crime_report_1.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6e455e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Field                                              Value\n",
      "0          Report Number                                        2024-001240\n",
      "1            Date & Time                                2013-08-11 18:00:00\n",
      "2      Reporting Officer                            Officer D. Morgan #6234\n",
      "3      Incident Location                                200 Block of 5TH ST\n",
      "4               Latitude                                  37.78091651016261\n",
      "5              Longitude                                  -122.404100362918\n",
      "6   Detailed Description  Petty theft from locked auto. Personal belongi...\n",
      "7        Police District                                           Southern\n",
      "8             Resolution                                               None\n",
      "9    Suspect Description                             No suspect identified.\n",
      "10    Victim Information                                          Anonymous\n"
     ]
    }
   ],
   "source": [
    "# Open the PDF using pdfplumber and extract text from all pages\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    full_text = \"\"\n",
    "    \n",
    "    for page in pdf.pages:      # Iterate through each page of the PDF\n",
    "        extracted_text = page.extract_text()        # Extract text from the page\n",
    "        if extracted_text:          # Check if text is extracted\n",
    "            full_text += extracted_text + \"\\n\"      # Append text to full_text\n",
    "\n",
    "# Split the extractetd text into individual lines\n",
    "lines = full_text.split(\"\\n\")\n",
    "\n",
    "# Create a list to store field-value pairs\n",
    "data = []\n",
    "pattern = r\"^(.*?):\\s*(.*)$\"  # Regex to capture \"Field: Value\" pattern\n",
    "current_field = None\n",
    "current_value = []\n",
    "\n",
    "# Loop through each line to find field-value pairs\n",
    "for line in lines:\n",
    "    line = line.strip()            # Remove leading/trailing whitespace\n",
    "    \n",
    "    # Check if the line matches the \"Field: Value\" pattern\n",
    "    match = re.match(pattern, line)\n",
    "    if match:\n",
    "        # If there's an existing field-value pair, save it to data\n",
    "        if current_field:\n",
    "            data.append([current_field, \" \".join(current_value).strip()])\n",
    "        \n",
    "        # Start a new field-value pair\n",
    "        current_field, value = match.groups()\n",
    "        current_value = [value.strip()]\n",
    "    else:\n",
    "        # If it's a continuation of the previous field (multi-line value)\n",
    "        if current_value:\n",
    "            current_value.append(line.strip())\n",
    "\n",
    "# After the loop, Add the last field-value pair to the data list\n",
    "if current_field:\n",
    "    data.append([current_field, \" \".join(current_value).strip()])\n",
    "\n",
    "# Convert the list of field-value pairs into a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Field\", \"Value\"])\n",
    "\n",
    "# Extract Latitude & Longitude from the \"Coordinates\" fields\n",
    "coord_index = df[df[\"Field\"] == \"Coordinates\"].index\n",
    "\n",
    "# If coordinates are found, separate them into latitude and longitude\n",
    "if not coord_index.empty:\n",
    "    coord_index = coord_index[0]\n",
    "    coords = df.at[coord_index, \"Value\"]\n",
    "    \n",
    "    # Extract latitude and longitude using regex\n",
    "    coord_match = re.match(r\"\\((-?\\d+\\.\\d+),\\s*(-?\\d+\\.\\d+)\\)\", coords)\n",
    "    \n",
    "    if coord_match:\n",
    "        latitude, longitude = coord_match.groups()\n",
    "        df.at[coord_index, \"Field\"] = \"Latitude\"        # Replace \"Coordinates\" with \"Latitude\"\n",
    "        df.at[coord_index, \"Value\"] = latitude\n",
    "        df.loc[coord_index + 0.5] = [\"Longitude\", longitude]  # Insert new row for Longitude\n",
    "    \n",
    "    # Reset the DataFrame and reset the index for clean output\n",
    "    df = df.sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Print the DataFrame for verification\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7be17e",
   "metadata": {},
   "source": [
    "### 🔷 PART B : PDF Text Extraction, Crime Categorization, and Severity Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44fbb348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.25.4)\n",
      "Vectorizer trained and saved successfully!\n",
      "Extracted PDF Text:\n",
      " City Police Department \n",
      "Official Police Crime Report \n",
      " \n",
      "Report Number: \n",
      "2024-001240 \n",
      "Date & Time: \n",
      "2013-08-11 18:00:00 \n",
      "Reporting Officer: \n",
      "Officer D. Morgan #6234 \n",
      "Incident Location: \n",
      "200 Block of 5TH ST \n",
      "Coordinates: \n",
      "(37.78091651016261, -122.404100362918) \n",
      "Detailed Description: \n",
      "Petty theft from locked auto. Personal belongings were stolen from a \n",
      "parked vehicle. \n",
      "Police District: \n",
      "Southern \n",
      "Resolution: \n",
      "None \n",
      "Suspect Description: \n",
      "No suspect identified. \n",
      "Victim Information: \n",
      "Anonymous \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Extracted Data:\n",
      " {'Date & Time': '2013-08-11 18:00:00', 'Detailed Description': 'Petty theft from locked auto. Personal belongings were stolen from a \\nparked vehicle.', 'Police District': 'Southern \\nResolution', 'Incident Location': '200 Block of 5TH ST', 'Resolution': 'None', 'Latitude': '37.78091651016261', 'Longitude': '-122.404100362918', 'DayOfWeek': 'Sunday'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DeLL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\DeLL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\DeLL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 1.0.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\DeLL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully added to crime_data_with_severity.csv\n"
     ]
    }
   ],
   "source": [
    "# Install pymupdf for PDF text extraction\n",
    "!pip install pymupdf\n",
    "\n",
    "import fitz  # PyMuPDF for PDF extraction\n",
    "import pandas as pd        # Library for handling data in DataFrame\n",
    "import re       # Regular expressions for pattern matching\n",
    "from datetime import datetime       # For handling date/time conversion\n",
    "import joblib   # For saving and loading models\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer         # For text vectorization\n",
    "\n",
    "# **Step 1: Extract text from PDF**\n",
    "def extract_text_from_pdf(pdf_path):        # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_text = \"\"\n",
    "\n",
    "#loop through each page and extract text\n",
    "    for page in doc:\n",
    "        extracted_text += page.get_text(\"text\") + \"\\n\"\n",
    "\n",
    "    # Print extracted text for debugging\n",
    "    print(\"Extracted PDF Text:\\n\", extracted_text)\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# **Step 2: Extract relevant crime details from the text using regex**\n",
    "def extract_crime_details(text):\n",
    "    extracted_data = {}\n",
    "\n",
    "    # Regex patterns to capture relevant fields\n",
    "    extracted_data[\"Date & Time\"] = re.search(r\"Date & Time:\\s*([\\d-]+\\s+\\d{2}:\\d{2}:\\d{2})\", text)\n",
    "    extracted_data[\"Detailed Description\"] = re.search(r\"Detailed Description:\\s*(.+?)(?=\\n[A-Z])\", text, re.DOTALL)\n",
    "    extracted_data[\"Police District\"] = re.search(r\"Police District:\\s*([A-Za-z\\s]+)\", text)\n",
    "    extracted_data[\"Incident Location\"] = re.search(r\"Incident Location:\\s*(.+)\", text)\n",
    "    extracted_data[\"Resolution\"] = re.search(r\"Resolution:\\s*(.+)\", text)\n",
    "\n",
    "    # Extract and clean data\n",
    "    for key, match in extracted_data.items():\n",
    "        extracted_data[key] = match.group(1).strip() if match else \"Unknown\"\n",
    "\n",
    "   # Extract Coordinates (Latitude & Longitude together)\n",
    "    coordinates_match = re.search(r\"Coordinates:\\s*\\(([-+]?\\d*\\.\\d+),\\s*([-+]?\\d*\\.\\d+)\\)\", text)\n",
    "    \n",
    "    if coordinates_match:\n",
    "        extracted_data[\"Latitude\"] = coordinates_match.group(1).strip()\n",
    "        extracted_data[\"Longitude\"] = coordinates_match.group(2).strip()\n",
    "    else:\n",
    "        extracted_data[\"Latitude\"] = \"Unknown\"\n",
    "        extracted_data[\"Longitude\"] = \"Unknown\"\n",
    "\n",
    "    # Extract and clean other fields\n",
    "    for key, match in extracted_data.items():\n",
    "        extracted_data[key] = match.strip() if isinstance(match, str) else \"Unknown\"\n",
    "        \n",
    "    # Convert date format and extract day of the week\n",
    "    if extracted_data[\"Date & Time\"] != \"Unknown\":\n",
    "        extracted_data[\"DayOfWeek\"] = datetime.strptime(extracted_data[\"Date & Time\"], \"%Y-%m-%d %H:%M:%S\").strftime(\"%A\")\n",
    "    else:\n",
    "        extracted_data[\"DayOfWeek\"] = \"Unknown\"\n",
    "\n",
    "    print(\"\\nExtracted Data:\\n\", extracted_data)  # Debugging step\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "# Function to assign severity based on category\n",
    "def assign_severity(category):\n",
    "    severity_mapping = {\n",
    "        \"NON-CRIMINAL\": 1, \"SUSPICIOUS OCC\": 1, \"MISSING PERSON\": 1, \"RUNAWAY\": 1, \"RECOVERED VEHICLE\": 1,\n",
    "        \"WARRANTS\": 2, \"OTHER OFFENSES\": 2, \"VANDALISM\": 2, \"TRESPASS\": 2, \"DISORDERLY CONDUCT\": 2, \"BAD CHECKS\": 2,\n",
    "        \"LARCENY/THEFT\": 3, \"VEHICLE THEFT\": 3, \"FORGERY/COUNTERFEITING\": 3, \"DRUG/NARCOTIC\": 3,\n",
    "        \"STOLEN PROPERTY\": 3, \"FRAUD\": 3, \"BRIBERY\": 3, \"EMBEZZLEMENT\": 3,\n",
    "        \"ROBBERY\": 4, \"WEAPON LAWS\": 4, \"BURGLARY\": 4, \"EXTORTION\": 4,\n",
    "        \"KIDNAPPING\": 5, \"ARSON\": 5\n",
    "    }\n",
    "    return severity_mapping.get(category, -1)  # Assign -1 if unknown\n",
    "\n",
    "# Load existing dataset of crime data with severity\n",
    "df = pd.read_csv(\"crime_data_with_severity.csv\")\n",
    "\n",
    "# Check for missing values and drop them\n",
    "df = df.dropna(subset=[\"Descript\", \"Category\"])\n",
    "\n",
    "# Extract descriptions and categories\n",
    "descriptions = df[\"Descript\"].astype(str).tolist()\n",
    "categories = df[\"Category\"].astype(str).tolist()\n",
    "\n",
    "# Fit vectorizer on crime descriptions\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(descriptions)\n",
    "\n",
    "# Save vectorizer\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
    "print(\"Vectorizer trained and saved successfully!\")\n",
    "\n",
    "# Load a pre-trained machine learning model for crime category prediction\n",
    "model = joblib.load(\"crime_category_model.pkl\")\n",
    "\n",
    "# Example: Extracted description from PDF\n",
    "description = \"Petty theft from locked auto. Personal belongings were stolen from a parked vehicle.\"\n",
    "\n",
    "# Transform input text\n",
    "description_vectorized = vectorizer.transform([description])\n",
    "\n",
    "# Predict crime category\n",
    "predicted_category = model.predict([description])[0]\n",
    "\n",
    "# Assign a severity level based on the predicted category\n",
    "predicted_severity = assign_severity(predicted_category)\n",
    "\n",
    "# New crime report entry\n",
    "def update_csv_with_extracted_data(pdf_path, csv_file):\n",
    "    # Extract text from PDF\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Extract relevant crime details\n",
    "    extracted_data = extract_crime_details(text)\n",
    "\n",
    "    # Read the existing CSV file\n",
    "    existing_df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Ensure extracted values are properly formatted\n",
    "    extracted_data[\"Police District\"] = extracted_data[\"Police District\"].split(\"\\n\")[0].strip()\n",
    "    extracted_data[\"Resolution\"] = extracted_data[\"Resolution\"].strip() if extracted_data[\"Resolution\"] else None\n",
    "\n",
    "\n",
    "    # Create a new row with only matching columns\n",
    "    new_row = {\n",
    "    \"Dates\": extracted_data[\"Date & Time\"],\n",
    "    \"Category\": predicted_category,\n",
    "    \"Descript\": description,\n",
    "    \"DayOfWeek\": extracted_data[\"DayOfWeek\"],\n",
    "    \"PdDistrict\": extracted_data[\"Police District\"],\n",
    "    \"Resolution\": extracted_data[\"Resolution\"],\n",
    "    \"Address\": extracted_data[\"Incident Location\"],\n",
    "    \"Latitude (Y)\": extracted_data[\"Latitude\"],\n",
    "    \"Longitude (X)\": extracted_data[\"Longitude\"],\n",
    "    \"Severity\": predicted_severity\n",
    "}\n",
    "    # Append the new row to the dataframe\n",
    "    updated_df = pd.concat([existing_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    updated_df.to_csv(csv_file, index=False)\n",
    "\n",
    "    print(\"✅ Data successfully added to\", csv_file)\n",
    "# **Run the function with a new PDF Crime report and update the csv file\n",
    "\n",
    "\n",
    "################################################ SELECT NEW PDF CRIME REPORT HERE ###################################################\n",
    "\n",
    "pdf_file = \"police_reports/police_crime_report_1.pdf\"  # Update with the PDF File desired to extract\n",
    "csv_file = \"crime_data_with_severity.csv\"  # Update with the existing CSV File\n",
    "\n",
    "update_csv_with_extracted_data(pdf_file, csv_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b2e75",
   "metadata": {},
   "source": [
    "# Level 4 Part A & B: Done✅\n",
    "## Next: Level 4 Part C 🖥️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
