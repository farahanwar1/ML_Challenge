{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf6b6e5",
   "metadata": {},
   "source": [
    "PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6e455e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\96892\\desktop\\streamlit\\.venv\\lib\\site-packages (0.11.5)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\96892\\desktop\\streamlit\\.venv\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\96892\\desktop\\streamlit\\.venv\\lib\\site-packages (from pdfplumber) (11.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\96892\\desktop\\streamlit\\.venv\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\96892\\desktop\\streamlit\\.venv\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\96892\\desktop\\streamlit\\.venv\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (44.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\96892\\desktop\\streamlit\\.venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\96892\\desktop\\streamlit\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "                   Field                                              Value\n",
      "0          Report Number                                        2024-001240\n",
      "1            Date & Time                                2013-08-11 18:00:00\n",
      "2      Reporting Officer                            Officer D. Morgan #6234\n",
      "3      Incident Location                                200 Block of 5TH ST\n",
      "4               Latitude                                  37.78091651016261\n",
      "5              Longitude                                  -122.404100362918\n",
      "6   Detailed Description  Petty theft from locked auto. Personal belongi...\n",
      "7        Police District                                           Southern\n",
      "8             Resolution                                               None\n",
      "9    Suspect Description                             No suspect identified.\n",
      "10    Victim Information                                          Anonymous\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_path = \"police_reports/police_crime_report_1.pdf\"\n",
    "\n",
    "# Open the PDF and extract text\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    full_text = \"\"\n",
    "    \n",
    "    for page in pdf.pages:\n",
    "        extracted_text = page.extract_text()\n",
    "        if extracted_text:\n",
    "            full_text += extracted_text + \"\\n\"\n",
    "\n",
    "# Split text into lines\n",
    "lines = full_text.split(\"\\n\")\n",
    "\n",
    "# Extract key-value pairs dynamically\n",
    "data = []\n",
    "pattern = r\"^(.*?):\\s*(.*)$\"  # Regex to capture \"Field: Value\" pattern\n",
    "current_field = None\n",
    "current_value = []\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Match \"Field: Value\" pattern\n",
    "    match = re.match(pattern, line)\n",
    "    if match:\n",
    "        # If there's an existing field-value pair, save it\n",
    "        if current_field:\n",
    "            data.append([current_field, \" \".join(current_value).strip()])\n",
    "        \n",
    "        # Start a new field\n",
    "        current_field, value = match.groups()\n",
    "        current_value = [value.strip()]\n",
    "    else:\n",
    "        # If it's a continuation of the previous field (multi-line value)\n",
    "        if current_value:\n",
    "            current_value.append(line.strip())\n",
    "\n",
    "# Add the last field-value pair to the data list\n",
    "if current_field:\n",
    "    data.append([current_field, \" \".join(current_value).strip()])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Field\", \"Value\"])\n",
    "\n",
    "# **Extract Latitude & Longitude separately**\n",
    "coord_index = df[df[\"Field\"] == \"Coordinates\"].index\n",
    "\n",
    "if not coord_index.empty:\n",
    "    coord_index = coord_index[0]\n",
    "    coords = df.at[coord_index, \"Value\"]\n",
    "    \n",
    "    # Extract latitude and longitude using regex\n",
    "    coord_match = re.match(r\"\\((-?\\d+\\.\\d+),\\s*(-?\\d+\\.\\d+)\\)\", coords)\n",
    "    \n",
    "    if coord_match:\n",
    "        latitude, longitude = coord_match.groups()\n",
    "        df.at[coord_index, \"Field\"] = \"Latitude\"\n",
    "        df.at[coord_index, \"Value\"] = latitude\n",
    "        df.loc[coord_index + 0.5] = [\"Longitude\", longitude]  # Insert new row\n",
    "    \n",
    "    # Reset index for clean output\n",
    "    df = df.sort_index().reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "#df.to_csv(\"formatted_report.csv\", index=False)\n",
    "\n",
    "# Print table for verification\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7be17e",
   "metadata": {},
   "source": [
    "PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44fbb348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\96892\\desktop\\streamlit\\.venv\\lib\\site-packages (1.25.4)\n",
      "Vectorizer trained and saved successfully!\n",
      "Extracted PDF Text:\n",
      " City Police Department \n",
      "Official Police Crime Report \n",
      " \n",
      "Report Number: \n",
      "2024-001243 \n",
      "Date & Time: \n",
      "2008-09-20 09:00:00 \n",
      "Reporting Officer: \n",
      "Officer J. Anderson #9567 \n",
      "Incident Location: \n",
      "200 Block of JONES ST \n",
      "Coordinates: \n",
      "(37.7834687204586, -122.412573643201) \n",
      "Detailed Description: \n",
      "Burglary of apartment house, unlawful entry. Suspect forced entry \n",
      "and stole electronics. \n",
      "Police District: \n",
      "Tenderloin \n",
      "Resolution: \n",
      "None \n",
      "Suspect Description: \n",
      "Unknown suspect, possible forced entry. \n",
      "Victim Information: \n",
      "Resident reported stolen items. \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Extracted Data:\n",
      " {'Date & Time': '2008-09-20 09:00:00', 'Detailed Description': 'Burglary of apartment house, unlawful entry. Suspect forced entry \\nand stole electronics.', 'Police District': 'Tenderloin \\nResolution', 'Incident Location': '200 Block of JONES ST', 'Resolution': 'None', 'Latitude': '37.7834687204586', 'Longitude': '-122.412573643201', 'DayOfWeek': 'Saturday'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\96892\\Desktop\\STREAMLIT\\.venv\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\96892\\Desktop\\STREAMLIT\\.venv\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\96892\\Desktop\\STREAMLIT\\.venv\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 1.0.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\96892\\Desktop\\STREAMLIT\\.venv\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully added to crime_data_with_severity.csv\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "import fitz  # PyMuPDF for PDF extraction\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# **Step 1: Extract text from PDF**\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    for page in doc:\n",
    "        extracted_text += page.get_text(\"text\") + \"\\n\"\n",
    "\n",
    "    # Print extracted text for debugging\n",
    "    print(\"Extracted PDF Text:\\n\", extracted_text)\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# **Step 2: Extract relevant data using regex**\n",
    "def extract_crime_details(text):\n",
    "    extracted_data = {}\n",
    "\n",
    "    # Regex patterns to capture relevant fields\n",
    "    extracted_data[\"Date & Time\"] = re.search(r\"Date & Time:\\s*([\\d-]+\\s+\\d{2}:\\d{2}:\\d{2})\", text)\n",
    "    extracted_data[\"Detailed Description\"] = re.search(r\"Detailed Description:\\s*(.+?)(?=\\n[A-Z])\", text, re.DOTALL)\n",
    "    extracted_data[\"Police District\"] = re.search(r\"Police District:\\s*([A-Za-z\\s]+)\", text)\n",
    "    extracted_data[\"Incident Location\"] = re.search(r\"Incident Location:\\s*(.+)\", text)\n",
    "    extracted_data[\"Resolution\"] = re.search(r\"Resolution:\\s*(.+)\", text)\n",
    "    #extracted_data[\"Coordinates\"] = re.search(r\"Coordinates:\\s*\\(([-+]?\\d*\\.\\d+),\\s*([-+]?\\d*\\.\\d+)\\)\", text)\n",
    "\n",
    "    # Extract and clean data\n",
    "    for key, match in extracted_data.items():\n",
    "        extracted_data[key] = match.group(1).strip() if match else \"Unknown\"\n",
    "\n",
    "   # Extract Coordinates (Latitude & Longitude together)\n",
    "    coordinates_match = re.search(r\"Coordinates:\\s*\\(([-+]?\\d*\\.\\d+),\\s*([-+]?\\d*\\.\\d+)\\)\", text)\n",
    "    \n",
    "    if coordinates_match:\n",
    "        extracted_data[\"Latitude\"] = coordinates_match.group(1).strip()\n",
    "        extracted_data[\"Longitude\"] = coordinates_match.group(2).strip()\n",
    "    else:\n",
    "        extracted_data[\"Latitude\"] = \"Unknown\"\n",
    "        extracted_data[\"Longitude\"] = \"Unknown\"\n",
    "\n",
    "    # Extract and clean other fields\n",
    "    for key, match in extracted_data.items():\n",
    "        extracted_data[key] = match.strip() if isinstance(match, str) else \"Unknown\"\n",
    "        \n",
    "    # Convert date format and extract day of the week\n",
    "    if extracted_data[\"Date & Time\"] != \"Unknown\":\n",
    "        extracted_data[\"DayOfWeek\"] = datetime.strptime(extracted_data[\"Date & Time\"], \"%Y-%m-%d %H:%M:%S\").strftime(\"%A\")\n",
    "    else:\n",
    "        extracted_data[\"DayOfWeek\"] = \"Unknown\"\n",
    "\n",
    "    print(\"\\nExtracted Data:\\n\", extracted_data)  # Debugging step\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "###########\n",
    "\n",
    "\n",
    "# Function to assign severity based on category\n",
    "def assign_severity(category):\n",
    "    severity_mapping = {\n",
    "        \"NON-CRIMINAL\": 1, \"SUSPICIOUS OCC\": 1, \"MISSING PERSON\": 1, \"RUNAWAY\": 1, \"RECOVERED VEHICLE\": 1,\n",
    "        \"WARRANTS\": 2, \"OTHER OFFENSES\": 2, \"VANDALISM\": 2, \"TRESPASS\": 2, \"DISORDERLY CONDUCT\": 2, \"BAD CHECKS\": 2,\n",
    "        \"LARCENY/THEFT\": 3, \"VEHICLE THEFT\": 3, \"FORGERY/COUNTERFEITING\": 3, \"DRUG/NARCOTIC\": 3,\n",
    "        \"STOLEN PROPERTY\": 3, \"FRAUD\": 3, \"BRIBERY\": 3, \"EMBEZZLEMENT\": 3,\n",
    "        \"ROBBERY\": 4, \"WEAPON LAWS\": 4, \"BURGLARY\": 4, \"EXTORTION\": 4,\n",
    "        \"KIDNAPPING\": 5, \"ARSON\": 5\n",
    "    }\n",
    "    return severity_mapping.get(category, -1)  # Assign -1 if unknown\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"crime_data_with_severity.csv\")\n",
    "\n",
    "# Check for missing values and drop them\n",
    "df = df.dropna(subset=[\"Descript\", \"Category\"])\n",
    "\n",
    "# Extract descriptions and categories\n",
    "descriptions = df[\"Descript\"].astype(str).tolist()\n",
    "categories = df[\"Category\"].astype(str).tolist()\n",
    "\n",
    "# Fit vectorizer on crime descriptions\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(descriptions)\n",
    "\n",
    "# Save vectorizer\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
    "print(\"Vectorizer trained and saved successfully!\")\n",
    "\n",
    "# Load trained model\n",
    "model = joblib.load(\"crime_category_model.pkl\")\n",
    "\n",
    "# Example: Extracted description from PDF\n",
    "description = \"Petty theft from locked auto. Personal belongings were stolen from a parked vehicle.\"\n",
    "\n",
    "# Transform input text\n",
    "description_vectorized = vectorizer.transform([description])\n",
    "\n",
    "# Predict category\n",
    "predicted_category = model.predict([description])[0]\n",
    "\n",
    "# Assign severity\n",
    "predicted_severity = assign_severity(predicted_category)\n",
    "\n",
    "# New crime report entry\n",
    "def update_csv_with_extracted_data(pdf_path, csv_file):\n",
    "    # Extract text from PDF\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Extract relevant crime details\n",
    "    extracted_data = extract_crime_details(text)\n",
    "\n",
    "    # Read the existing CSV file\n",
    "    existing_df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Ensure extracted values are properly formatted\n",
    "    extracted_data[\"Police District\"] = extracted_data[\"Police District\"].split(\"\\n\")[0].strip()\n",
    "    extracted_data[\"Resolution\"] = extracted_data[\"Resolution\"].strip() if extracted_data[\"Resolution\"] else None\n",
    "\n",
    "\n",
    "    # Create a new row with only matching columns\n",
    "    new_row = {\n",
    "    \"Dates\": extracted_data[\"Date & Time\"],\n",
    "    \"Category\": predicted_category,\n",
    "    \"Descript\": description,\n",
    "    \"DayOfWeek\": extracted_data[\"DayOfWeek\"],\n",
    "    \"PdDistrict\": extracted_data[\"Police District\"],\n",
    "    \"Resolution\": extracted_data[\"Resolution\"],\n",
    "    \"Address\": extracted_data[\"Incident Location\"],\n",
    "    \"Latitude (Y)\": extracted_data[\"Latitude\"],\n",
    "    \"Longitude (X)\": extracted_data[\"Longitude\"],\n",
    "    \"Severity\": predicted_severity\n",
    "}\n",
    "    # Append the new row to the dataframe\n",
    "    #updated_df = existing_df.append(new_row, ignore_index=True)\n",
    "    updated_df = pd.concat([existing_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    # Save the updated CSV file\n",
    "    updated_df.to_csv(csv_file, index=False)\n",
    "\n",
    "    print(\"✅ Data successfully added to\", csv_file)\n",
    "# **Run the function**\n",
    "############################## SELECT NEW PDF CRIME REPORT HERE #########################\n",
    "\n",
    "pdf_file = \"police_reports/police_crime_report_4.pdf\"  # Change this to your actual PDF file\n",
    "csv_file = \"crime_data_with_severity.csv\"  # Your existing CSV file\n",
    "\n",
    "update_csv_with_extracted_data(pdf_file, csv_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b2e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
